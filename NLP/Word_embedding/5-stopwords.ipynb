{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909b899b",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c14392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words is a common word in english language which is used to remove the unnecessary words from the text like a ,the,etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce173148",
   "metadata": {},
   "outputs": [],
   "source": [
    "## why stopwords are removed?\n",
    "## 1. to reduce the size of the text\n",
    "## 2. to reduce the complexity of the text  \n",
    "## 2. to reduce the dimension of the text  \n",
    "## 2. to reduce the noise of the text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0be715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Akshat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9847b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7f20ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ea749bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"Artificial Intelligence (AI) represents both a remarkable leap forward in innovation and a significant challenge to societal norms and industries. In healthcare, AI is revolutionizing patient care by enabling more precise diagnostics, personalized treatment plans, and even robotic-assisted surgeries that promise faster recovery times and reduced human error. AI's applications in finance, from algorithmic trading to fraud detection, demonstrate its capacity to enhance efficiency and safeguard assets. In automotive industries, AI-driven autonomous vehicles hold the potential to redefine transportation,\"\n",
    "paragraph=paragraph.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8348ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial intelligence (ai) represents both a remarkable leap forward in innovation and a significant challenge to societal norms and industries.',\n",
       " 'in healthcare, ai is revolutionizing patient care by enabling more precise diagnostics, personalized treatment plans, and even robotic-assisted surgeries that promise faster recovery times and reduced human error.',\n",
       " \"ai's applications in finance, from algorithmic trading to fraud detection, demonstrate its capacity to enhance efficiency and safeguard assets.\",\n",
       " 'in automotive industries, ai-driven autonomous vehicles hold the potential to redefine transportation,']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.tokenize import sent_tokenize\n",
    "# sent=sent_tokenize(paragraph)\n",
    "# sent\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#paragraph = \"\"\"The quiet village of Eldenbrook lay nestled between rolling hills and dense forests, untouched by the rush of modern life. Cobblestone streets wound their way past quaint cottages with ivy-covered walls and colorful flower boxes beneath every window. Children played by the stream that ran through the center of town, while elders gathered in the square to share stories over steaming mugs of tea. Life moved slowly here, and that was just how the villagers liked itâ€”a peaceful rhythm in harmony with nature's gentle pace.\"\"\"\n",
    "\n",
    "\n",
    "sent = sent_tokenize(paragraph)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "691f6669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artifici intellig ( ai ) repres remark leap forward innov signific challeng societ norm industri .', 'healthcar , ai revolution patient care enabl precis diagnost , person treatment plan , even robotic-assist surgeri promis faster recoveri time reduc human error .', \"ai 's applic financ , algorithm trade fraud detect , demonstr capac enhanc effici safeguard asset .\", 'automot industri , ai-driven autonom vehicl hold potenti redefin transport ,']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(sent)):\n",
    "    words = nltk.word_tokenize(sent[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sent[i] = ' '.join(words)\n",
    "\n",
    "print(sent)\n",
    "# from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "# stemmer=PorterStemmer()\n",
    "# wordnet_lemmatizer=WordNetLemmatizer()  \n",
    "# for i in range (len(sent)):\n",
    "#     word=wordnet_lemmatizer.lemmatize(sent[i])\n",
    "#     words=[stemmer.stem(word) for word in word if word not in set(stopwords.words('english'))]\n",
    "#     sent[i]= ' '.join(words)\n",
    "# print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea02d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
